name: Deploy Application

on:
  workflow_dispatch: {}
  push:
    branches:
      - master

jobs:
  build:
    runs-on: ubuntu-latest
    outputs:
      s3object: ${{ steps.create_archive.outputs.archive_filename }}
      
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-region: ${{ secrets.AWS_REGION }}
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}      
      
    - name: Create archive
      id: create_archive
      run: |
        DATE=$(date +"%Y-%m-%d")
        git archive --format=tar.gz -o app_${DATE}.tar.gz HEAD
        echo "::set-output name=archive_filename::app_${DATE}.tar.gz"
      
    - name: Upload to S3
      run: |
        echo "Uploading to S3"
        aws s3 cp app_${{ needs.build.outputs.s3object }} s3://${{ secrets.S3_BUCKET_NAME }}/
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: ${{ secrets.AWS_REGION }}
    
    - name: Set expiry policy on S3 bucket
      run: |
        aws s3api put-bucket-lifecycle-configuration --bucket ${{ secrets.S3_BUCKET_NAME }} --lifecycle-configuration '{"Rules":[{"ID":"ExpireOldBuilds","Prefix":"","Status":"Enabled","Expiration":{"Days":7}}]}'
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: ${{ secrets.AWS_REGION }}

##########################################################################################################

  deploy:
    needs: build
    runs-on: ubuntu-latest

    steps:
    - name: Set up AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-region: ${{ secrets.AWS_REGION }}
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

    - name: Deploy to Auto Scaling Group
      env:
        PRIVATE_KEY: ${{ secrets.PRIVATE_KEY_PEM }}
      run: |
        # Get the instance IDs of instances in the Auto Scaling Group
        instance_ids=$(aws autoscaling describe-auto-scaling-groups --auto-scaling-group-name ${{ secrets.ASG_NAME }} --query 'AutoScalingGroups[].Instances[].InstanceId' --output text)
        echo "VMs IDs: $instance_ids"
        
        object_url=$(aws s3 presign s3://${{ secrets.S3_BUCKET_NAME }}/${{ needs.build.outputs.s3object }})
        echo "Object URL: $object_url"

        echo "$PRIVATE_KEY" > private_key && chmod 600 private_key

        echo "s3object: ${{ needs.build.outputs.s3object }}"

        # Iterate over each instance
        for instance_id in $instance_ids; do
          # Get the public IP address of the instance
          public_ip=$(aws ec2 describe-instances --instance-ids $instance_id --query 'Reservations[].Instances[].PublicIpAddress' --output text)

          # SSH into the instance and download the object from the S3 bucket
          ssh -o StrictHostKeyChecking=no -i private_key ec2-user@$public_ip "
            cd /var/www/html
            sudo wget \"$object_url\" -O ${{ needs.build.outputs.s3object }}
            sudo tar -xvzf ${{ needs.build.outputs.s3object }}
            sudo rm -rf ${{ needs.build.outputs.s3object }}
            sudo systemctl restart httpd
          " || true
        done
